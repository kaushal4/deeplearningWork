{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('myEnv')",
   "metadata": {
    "interpreter": {
     "hash": "bc668af03b3472d9fd6410ee988dd95cb020ab14ea4cb61513626b3dd5035d2a"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   age  affordibility  bought_insurance\n",
       "0   22              1                 0\n",
       "1   25              0                 0\n",
       "2   47              1                 1\n",
       "3   52              0                 0\n",
       "4   46              1                 1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>affordibility</th>\n      <th>bought_insurance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>22</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>25</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>47</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>52</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>46</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df = pd.read_csv(\"E:\\\\machine learning\\\\learningDL\\\\insurance_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['age','affordibility']],df.bought_insurance,test_size=0.2, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_scaled = X_train.copy()\n",
    "\n",
    "X_train_scaled['age'] = X_train_scaled['age'] / 100\n",
    "\n",
    "X_test_scaled = X_test.copy()\n",
    "X_test_scaled['age'] = X_test_scaled['age'] / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss(y_true, y_predicted):\n",
    "    epsilon = 1e-15\n",
    "    y_predicted_new = [max(i,epsilon) for i in y_predicted]\n",
    "    y_predicted_new = [min(i,1-epsilon) for i in y_predicted_new]\n",
    "    y_predicted_new = np.array(y_predicted_new)\n",
    "    return -np.mean(y_true*np.log(y_predicted_new)+(1-y_true)*np.log(1-y_predicted_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9999999847700205"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "\n",
    "def sigmoid(x):\n",
    "        import math\n",
    "        return 1 / (1 + math.exp(-x))\n",
    "sigmoid(18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.99999386, 0.5       , 0.73105858])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "def sigmoid_numpy(X):\n",
    "   return 1/(1+np.exp(-X))\n",
    "\n",
    "sigmoid_numpy(np.array([12,0,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def log_loss(y_true, y_predicted):\n",
    "    epsilon = 1e-15\n",
    "    y_predicted_new = [max(i,epsilon) for i in y_predicted]\n",
    "    y_predicted_new = [min(i,1-epsilon) for i in y_predicted_new]\n",
    "    y_predicted_new = np.array(y_predicted_new)\n",
    "    return -np.mean(y_true*np.log(y_predicted_new)+(1-y_true)*np.log(1-y_predicted_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myNN:\n",
    "    def __init__(self):\n",
    "        self.w1=1\n",
    "        self.w2=1\n",
    "        self.bias=0\n",
    "    def fit(self, X, y, epochs, loss_thresold):\n",
    "        self.w1, self.w2, self.bias = self.gradient_descent(X['age'],X['affordibility'],y, epochs, loss_thresold)\n",
    "        print(f\"Final weights and bias: w1: {self.w1}, w2: {self.w2}, bias: {self.bias}\")\n",
    "    def preidct(self,age,affordability):\n",
    "        weighted_sum = w1 * age + w2 * affordability + bias\n",
    "        y_predicted = sigmoid_numpy(weighted_sum)\n",
    "        print(y_predicted)\n",
    "    def gradient_descent(self, age,affordability, y_true, epochs, loss_thresold):\n",
    "        w1 = w2 = 1\n",
    "        bias = 0\n",
    "        rate = 0.5\n",
    "        n = len(age)\n",
    "        for i in range(epochs):\n",
    "            weighted_sum = w1 * age + w2 * affordability + bias\n",
    "            y_predicted = sigmoid_numpy(weighted_sum)\n",
    "            loss = log_loss(y_true, y_predicted)\n",
    "            \n",
    "            w1d = (1/n)*np.dot(np.transpose(age),(y_predicted-y_true)) \n",
    "            w2d = (1/n)*np.dot(np.transpose(affordability),(y_predicted-y_true)) \n",
    "\n",
    "            bias_d = np.mean(y_predicted-y_true)\n",
    "            w1 = w1 - rate * w1d\n",
    "            w2 = w2 - rate * w2d\n",
    "            bias = bias - rate * bias_d\n",
    "            \n",
    "            if i%50==0:\n",
    "                print (f'Epoch:{i}, w1:{w1}, w2:{w2}, bias:{bias}, loss:{loss}')\n",
    "            \n",
    "            if loss<=loss_thresold:\n",
    "                print (f'Epoch:{i}, w1:{w1}, w2:{w2}, bias:{bias}, loss:{loss}')\n",
    "                break\n",
    "\n",
    "        return w1, w2, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch:0, w1:0.974907633470177, w2:0.948348125394529, bias:-0.11341867736368583, loss:0.7113403233723417\nEpoch:50, w1:1.5033195541731388, w2:1.108384790367645, bias:-1.2319047301235464, loss:0.5675865113475955\nEpoch:100, w1:2.200713131760032, w2:1.2941584023238903, bias:-1.6607009122062801, loss:0.5390680417774752\nEpoch:150, w1:2.8495727769689085, w2:1.3696895491572745, bias:-1.986105845859897, loss:0.5176462164249294\nEpoch:200, w1:3.443016970881803, w2:1.4042218624465033, bias:-2.2571369883752723, loss:0.5005011269691375\nEpoch:250, w1:3.982450494649576, w2:1.4239127329321233, bias:-2.494377365971801, loss:0.48654089537617085\nEpoch:300, w1:4.472179522095915, w2:1.438787986553552, bias:-2.707387811922373, loss:0.4750814640632793\nEpoch:350, w1:4.917245868007634, w2:1.4525660781176122, bias:-2.901176333556766, loss:0.46561475306999006\nEpoch:366, w1:5.051047623653049, w2:1.4569794548473887, bias:-2.9596534546250037, loss:0.46293944095888917\nFinal weights and bias: w1: 5.051047623653049, w2: 1.4569794548473887, bias: -2.9596534546250037\n"
     ]
    }
   ],
   "source": [
    "myModel = myNN();\n",
    "myModel.fit(X_train_scaled,y_train,8000,0.4631)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(22, 2)"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 4803/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.9091\n",
      "Epoch 4804/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.9091\n",
      "Epoch 4805/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.9091\n",
      "Epoch 4806/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.9091\n",
      "Epoch 4807/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.9091\n",
      "Epoch 4808/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.9091\n",
      "Epoch 4809/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.9091\n",
      "Epoch 4810/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4668 - accuracy: 0.9091\n",
      "Epoch 4811/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4667 - accuracy: 0.9091\n",
      "Epoch 4812/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.9091\n",
      "Epoch 4813/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4667 - accuracy: 0.9091\n",
      "Epoch 4814/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4667 - accuracy: 0.9091\n",
      "Epoch 4815/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.9091\n",
      "Epoch 4816/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4666 - accuracy: 0.9091\n",
      "Epoch 4817/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4666 - accuracy: 0.9091\n",
      "Epoch 4818/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.9091\n",
      "Epoch 4819/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.9091\n",
      "Epoch 4820/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.9091\n",
      "Epoch 4821/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4665 - accuracy: 0.9091\n",
      "Epoch 4822/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.9091\n",
      "Epoch 4823/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.9091\n",
      "Epoch 4824/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.9091\n",
      "Epoch 4825/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.9091\n",
      "Epoch 4826/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4664 - accuracy: 0.9091\n",
      "Epoch 4827/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4664 - accuracy: 0.9091\n",
      "Epoch 4828/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.9091\n",
      "Epoch 4829/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.9091\n",
      "Epoch 4830/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.9091\n",
      "Epoch 4831/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.9091\n",
      "Epoch 4832/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.9091\n",
      "Epoch 4833/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.9091\n",
      "Epoch 4834/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.9091\n",
      "Epoch 4835/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.9091\n",
      "Epoch 4836/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.9091\n",
      "Epoch 4837/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.9091\n",
      "Epoch 4838/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.9091\n",
      "Epoch 4839/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.9091\n",
      "Epoch 4840/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.9091\n",
      "Epoch 4841/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.9091\n",
      "Epoch 4842/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4661 - accuracy: 0.9091\n",
      "Epoch 4843/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.9091\n",
      "Epoch 4844/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.9091\n",
      "Epoch 4845/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.9091\n",
      "Epoch 4846/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.9091\n",
      "Epoch 4847/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.9091\n",
      "Epoch 4848/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.9091\n",
      "Epoch 4849/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.9091\n",
      "Epoch 4850/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.9091\n",
      "Epoch 4851/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.9091\n",
      "Epoch 4852/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.9091\n",
      "Epoch 4853/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.9091\n",
      "Epoch 4854/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.9091\n",
      "Epoch 4855/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.9091\n",
      "Epoch 4856/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.9091\n",
      "Epoch 4857/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.9091\n",
      "Epoch 4858/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.9091\n",
      "Epoch 4859/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.9091\n",
      "Epoch 4860/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.9091\n",
      "Epoch 4861/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.9091\n",
      "Epoch 4862/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.9091\n",
      "Epoch 4863/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.9091\n",
      "Epoch 4864/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.9091\n",
      "Epoch 4865/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.9091\n",
      "Epoch 4866/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.9091\n",
      "Epoch 4867/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4656 - accuracy: 0.9091\n",
      "Epoch 4868/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.9091\n",
      "Epoch 4869/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.9091\n",
      "Epoch 4870/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.9091\n",
      "Epoch 4871/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4656 - accuracy: 0.9091\n",
      "Epoch 4872/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.9091\n",
      "Epoch 4873/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.9091\n",
      "Epoch 4874/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.9091\n",
      "Epoch 4875/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.9091\n",
      "Epoch 4876/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.9091\n",
      "Epoch 4877/5000\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.4654 - accuracy: 0.9091\n",
      "Epoch 4878/5000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.9091\n",
      "Epoch 4879/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.9091\n",
      "Epoch 4880/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.9091\n",
      "Epoch 4881/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.9091\n",
      "Epoch 4882/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.9091\n",
      "Epoch 4883/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.9091\n",
      "Epoch 4884/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.9091\n",
      "Epoch 4885/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.9091\n",
      "Epoch 4886/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.9091\n",
      "Epoch 4887/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.9091\n",
      "Epoch 4888/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.9091\n",
      "Epoch 4889/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4652 - accuracy: 0.9091\n",
      "Epoch 4890/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4652 - accuracy: 0.9091\n",
      "Epoch 4891/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.9091\n",
      "Epoch 4892/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.9091\n",
      "Epoch 4893/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.9091\n",
      "Epoch 4894/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.9091\n",
      "Epoch 4895/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.9091\n",
      "Epoch 4896/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.9091\n",
      "Epoch 4897/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4650 - accuracy: 0.9091\n",
      "Epoch 4898/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.9091\n",
      "Epoch 4899/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.9091\n",
      "Epoch 4900/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.9091\n",
      "Epoch 4901/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.9091\n",
      "Epoch 4902/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4650 - accuracy: 0.9091\n",
      "Epoch 4903/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.9091\n",
      "Epoch 4904/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.9091\n",
      "Epoch 4905/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.9091\n",
      "Epoch 4906/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.9091\n",
      "Epoch 4907/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.9091\n",
      "Epoch 4908/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.9091\n",
      "Epoch 4909/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.9091\n",
      "Epoch 4910/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.9091\n",
      "Epoch 4911/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.9091\n",
      "Epoch 4912/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.9091\n",
      "Epoch 4913/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.9091\n",
      "Epoch 4914/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.9091\n",
      "Epoch 4915/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.9091\n",
      "Epoch 4916/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.9091\n",
      "Epoch 4917/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.9091\n",
      "Epoch 4918/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.9091\n",
      "Epoch 4919/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.9091\n",
      "Epoch 4920/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.9091\n",
      "Epoch 4921/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.9091\n",
      "Epoch 4922/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.9091\n",
      "Epoch 4923/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.9091\n",
      "Epoch 4924/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.9091\n",
      "Epoch 4925/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.9091\n",
      "Epoch 4926/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.9091\n",
      "Epoch 4927/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.9091\n",
      "Epoch 4928/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4644 - accuracy: 0.9091\n",
      "Epoch 4929/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.9091\n",
      "Epoch 4930/5000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4644 - accuracy: 0.9091\n",
      "Epoch 4931/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.9091\n",
      "Epoch 4932/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.9091\n",
      "Epoch 4933/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.9091\n",
      "Epoch 4934/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.9091\n",
      "Epoch 4935/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.9091\n",
      "Epoch 4936/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.9091\n",
      "Epoch 4937/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.9091\n",
      "Epoch 4938/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.9091\n",
      "Epoch 4939/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.9091\n",
      "Epoch 4940/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.9091\n",
      "Epoch 4941/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.9091\n",
      "Epoch 4942/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.9091\n",
      "Epoch 4943/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.9091\n",
      "Epoch 4944/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.9091\n",
      "Epoch 4945/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.9091\n",
      "Epoch 4946/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.9091\n",
      "Epoch 4947/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.9091\n",
      "Epoch 4948/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.9091\n",
      "Epoch 4949/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.9091\n",
      "Epoch 4950/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4640 - accuracy: 0.9091\n",
      "Epoch 4951/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.9091\n",
      "Epoch 4952/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4640 - accuracy: 0.9091\n",
      "Epoch 4953/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.9091\n",
      "Epoch 4954/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.9091\n",
      "Epoch 4955/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.9091\n",
      "Epoch 4956/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4639 - accuracy: 0.9091\n",
      "Epoch 4957/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.9091\n",
      "Epoch 4958/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.9091\n",
      "Epoch 4959/5000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.9091\n",
      "Epoch 4960/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.9091\n",
      "Epoch 4961/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.9091\n",
      "Epoch 4962/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.9091\n",
      "Epoch 4963/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.9091\n",
      "Epoch 4964/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.9091\n",
      "Epoch 4965/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.9091\n",
      "Epoch 4966/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.9091\n",
      "Epoch 4967/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.9091\n",
      "Epoch 4968/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.9091\n",
      "Epoch 4969/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.9091\n",
      "Epoch 4970/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.9091\n",
      "Epoch 4971/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.9091\n",
      "Epoch 4972/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.9091\n",
      "Epoch 4973/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.9091\n",
      "Epoch 4974/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.9091\n",
      "Epoch 4975/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.9091\n",
      "Epoch 4976/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.9091\n",
      "Epoch 4977/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.9091\n",
      "Epoch 4978/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.9091\n",
      "Epoch 4979/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.9091\n",
      "Epoch 4980/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.9091\n",
      "Epoch 4981/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.9091\n",
      "Epoch 4982/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.9091\n",
      "Epoch 4983/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.9091\n",
      "Epoch 4984/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.9091\n",
      "Epoch 4985/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.9091\n",
      "Epoch 4986/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.9091\n",
      "Epoch 4987/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.9091\n",
      "Epoch 4988/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.9091\n",
      "Epoch 4989/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.9091\n",
      "Epoch 4990/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.9091\n",
      "Epoch 4991/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.9091\n",
      "Epoch 4992/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.9091\n",
      "Epoch 4993/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.9091\n",
      "Epoch 4994/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.9091\n",
      "Epoch 4995/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.9091\n",
      "Epoch 4996/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.9091\n",
      "Epoch 4997/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.9091\n",
      "Epoch 4998/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.9091\n",
      "Epoch 4999/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.9091\n",
      "Epoch 5000/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.9091\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f83dc011f0>"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(1, input_shape=(2,), activation='sigmoid', kernel_initializer='ones', bias_initializer='zeros')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_scaled, y_train, epochs=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([[5.060868],\n",
       "        [1.40865 ]], dtype=float32),\n",
       " array([-2.913703], dtype=float32))"
      ]
     },
     "metadata": {},
     "execution_count": 77
    }
   ],
   "source": [
    "coef, intercept = model.get_weights()\n",
    "coef, intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}